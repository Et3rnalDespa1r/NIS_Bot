import asyncio
import aiohttp
import logging
import random
import os
from menu_items import menu_urls
from bs4 import BeautifulSoup

BASE_URL = "https://coffeemania.ru"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ —Ä–∞–Ω–¥–æ–º–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π (–∞–Ω—Ç–∏-–±–∞–Ω)
async def fetch(url, session, retries=3, delay_range=(1, 3)):
    for attempt in range(retries):
        try:
            # –†–∞–Ω–¥–æ–º–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
            delay = random.uniform(*delay_range)
            await asyncio.sleep(delay)
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    return await response.text()
                else:
                    logging.error(f"–û—à–∏–±–∫–∞ {response.status} –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}")
        except Exception as e:
            logging.exception(f"Exception –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}: {e}")
        logging.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞ {url} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries})")
    return None


# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ SVG)
async def download_image(img_url, session, category, dish_name):
    if not img_url or img_url == "–ù–µ—Ç —Ñ–æ—Ç–æ":
        return "–ù–µ—Ç —Ñ–æ—Ç–æ"
    try:
        async with session.get(img_url, timeout=10) as response:
            if response.status != 200:
                logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_url} (—Å—Ç–∞—Ç—É—Å {response.status})")
                return img_url
            img_bytes = await response.read()
    except Exception as e:
        logging.exception(f"Exception –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_url}: {e}")
        return img_url

    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    dir_path = os.path.join("images", category)
    os.makedirs(dir_path, exist_ok=True)

    # –§–æ—Ä–º–∏—Ä—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    safe_dish_name = "".join(c for c in dish_name if c.isalnum() or c in " _-").strip()
    file_extension = os.path.splitext(img_url)[1].lower() if '.' in img_url else '.jpg'
    output_path = os.path.join(dir_path, f"{safe_dish_name}{file_extension}")

    try:
        with open(output_path, "wb") as f:
            f.write(img_bytes)
        return output_path
    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_url}: {e}")
        return img_url


# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–ª—é–¥–∞
async def parse_dish(url, session, category, semaphore):
    async with semaphore:
        html = await fetch(url, session)
        if html is None:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}")
            return None

        try:
            soup = BeautifulSoup(html, "html.parser")
            item_info = soup.find("div", id="itemInfo")
            if not item_info:
                logging.error(f"–ë–ª–æ–∫ itemInfo –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ {url}")
                return None

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
            name_tag = item_info.find("h1", class_="itemTitle")
            name = name_tag.text.strip() if name_tag else "–ù–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è"
            description_tag = item_info.find("div", class_="itemDesc")
            description = description_tag.text.strip() if description_tag else "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
            price_tag = item_info.find("div", class_="itemPrice")
            price = price_tag.text.strip() if price_tag else "–ù–µ—Ç —Ü–µ–Ω—ã"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∏—â–µ–≤—É—é —Ü–µ–Ω–Ω–æ—Å—Ç—å
            nutrition_values = {}
            nutrition_section = item_info.find("div", class_="itemAboutValueContent")
            if nutrition_section:
                for stat in nutrition_section.find_all("div", class_="itemStat"):
                    key_tag = stat.find("span")
                    if key_tag:
                        key = key_tag.text.strip()
                        value = stat.text.replace(key, "").replace("\xa0", " ").strip()
                        nutrition_values[key] = value

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ—Å—Ç–∞–≤
            composition = "–ù–µ—Ç —Å–æ—Å—Ç–∞–≤–∞"
            composition_section = item_info.find("div", class_="itemAboutCompositionContent")
            if composition_section:
                composition_p = composition_section.find("p")
                if composition_p:
                    composition = composition_p.text.strip()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–ª–ª–µ—Ä–≥–µ–Ω–∞—Ö
            allergens_section = item_info.find("p", style="font-style: italic")
            allergens = allergens_section.text.strip() if allergens_section else "–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∫–∞—Ä—Ç–∏–Ω–∫–∏:
            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –±–ª–æ–∫ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ (itemSlider)
            slider = soup.find("div", id="itemSlider")
            if slider:
                first_slide = slider.find("div", class_="itemSlide")
                if first_slide:
                    img_tag = first_slide.find("img", itemprop="contentUrl")
                    if img_tag and img_tag.has_attr("src"):
                        img_url = img_tag["src"]
                    else:
                        img_url = "–ù–µ—Ç —Ñ–æ—Ç–æ"
                else:
                    img_url = "–ù–µ—Ç —Ñ–æ—Ç–æ"
            else:
                # –ï—Å–ª–∏ –±–ª–æ–∫–∞ itemSlider –Ω–µ—Ç, –∏—â–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ
                img_tag = item_info.find("img")
                img_url = img_tag["src"] if img_tag and img_tag.has_attr("src") else "–ù–µ—Ç —Ñ–æ—Ç–æ"

            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ "–ù–µ—Ç —Ñ–æ—Ç–æ" ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
            if img_url != "–ù–µ—Ç —Ñ–æ—Ç–æ":
                # –ï—Å–ª–∏ URL —Å–æ–¥–µ—Ä–∂–∏—Ç .svg, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º "–ù–µ—Ç —Ñ–æ—Ç–æ" (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
                if img_url.lower().endswith(".svg"):
                    img_url = "–ù–µ—Ç —Ñ–æ—Ç–æ"
                elif not img_url.startswith("http"):
                    img_url = BASE_URL + img_url

            # –°–∫–∞—á–∏–≤–∞–µ–º (–∏–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ "–ù–µ—Ç —Ñ–æ—Ç–æ")
            processed_img = await download_image(img_url, session, category, name)
            return {
                "–ù–∞–∑–≤–∞–Ω–∏–µ": name,
                "–¶–µ–Ω–∞": price,
                "–û–ø–∏—Å–∞–Ω–∏–µ": description,
                "–ü–∏—â–µ–≤–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å": nutrition_values,
                "–°–æ—Å—Ç–∞–≤": composition,
                "–ê–ª–ª–µ—Ä–≥–µ–Ω—ã": allergens,
                "–§–æ—Ç–æ": processed_img
            }
        except Exception as e:
            logging.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
            return None


# –û—Å–Ω–æ–≤–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
async def main():
    parsed_menu = {}
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–∞–Ω—Ç–∏-–±–∞–Ω)
    semaphore = asyncio.Semaphore(5)

    # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É SSL-—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞ (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è production)
    connector = aiohttp.TCPConnector(ssl=False)

    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = []  # –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL
        for category, content in menu_urls.items():
            parsed_menu[category] = {}
            logging.info(f"\n –ü–∞—Ä—Å–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é: {category}")

            # –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞–∑–¥–µ–ª "–ù–∞–ø–∏—Ç–∫–∏" (—Å–ª–æ–≤–∞—Ä—å —Å –ø–æ–¥–≥—Ä—É–ø–ø–∞–º–∏)
            if isinstance(content, dict):
                for subcategory, urls in content.items():
                    parsed_menu[category][subcategory] = []
                    for url in urls:
                        task = asyncio.create_task(parse_dish(url, session, category, semaphore))
                        tasks.append((category, subcategory, task))
            # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ã—á–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è (—Å–ø–∏—Å–æ–∫)
            else:
                parsed_menu[category] = []
                for url in content:
                    task = asyncio.create_task(parse_dish(url, session, category, semaphore))
                    tasks.append((category, None, task))

        # –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        for category, subcategory, task in tasks:
            dish = await task
            if dish:
                if subcategory:
                    parsed_menu[category][subcategory].append(dish)
                else:
                    parsed_menu[category].append(dish)

    # –ß–∏—Ç–∞–µ–º—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    for category, content in parsed_menu.items():
        print(f"\n–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
        if isinstance(content, dict):  # –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞–∑–¥–µ–ª "–ù–∞–ø–∏—Ç–∫–∏"
            for subcategory, dishes in content.items():
                print(f"\n –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è: {subcategory}")
                for dish in dishes:
                    print(f"\n–ù–∞–∑–≤–∞–Ω–∏–µ: {dish['–ù–∞–∑–≤–∞–Ω–∏–µ']}")
                    print(f"–¶–µ–Ω–∞: {dish['–¶–µ–Ω–∞']}")
                    print(f"–û–ø–∏—Å–∞–Ω–∏–µ: {dish['–û–ø–∏—Å–∞–Ω–∏–µ']}")
                    print(" –ü–∏—â–µ–≤–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å:")
                    for k, v in dish["–ü–∏—â–µ–≤–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å"].items():
                        print(f" {k}: {v}")
                    print(f"–°–æ—Å—Ç–∞–≤: {dish['–°–æ—Å—Ç–∞–≤']}")
                    print(f"{dish['–ê–ª–ª–µ—Ä–≥–µ–Ω—ã']}")
                    print(f"–§–æ—Ç–æ: {dish['–§–æ—Ç–æ']}")
                    print("-" * 50)
        else:  # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ã—á–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            for dish in content:
                print(f"\n–ù–∞–∑–≤–∞–Ω–∏–µ: {dish['–ù–∞–∑–≤–∞–Ω–∏–µ']}")
                print(f"–¶–µ–Ω–∞: {dish['–¶–µ–Ω–∞']}")
                print(f"–û–ø–∏—Å–∞–Ω–∏–µ: {dish['–û–ø–∏—Å–∞–Ω–∏–µ']}")
                print(" –ü–∏—â–µ–≤–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å:")
                for k, v in dish["–ü–∏—â–µ–≤–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å"].items():
                    print(f"   {k}: {v}")
                print(f"–°–æ—Å—Ç–∞–≤: {dish['–°–æ—Å—Ç–∞–≤']}")
                print(f"{dish['–ê–ª–ª–µ—Ä–≥–µ–Ω—ã']}")
                print(f"–§–æ—Ç–æ: {dish['–§–æ—Ç–æ']}")
                print("-" * 50)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logging.exception(f"–û—à–∏–±–∫–∞: {e}")